<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Context Parametric Inversion</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>

  <header>
    <h1>Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance</h1>
    <h3>Sachin Goyal<sup>1</sup>, Christina Baek<sup>1</sup>, Zico Kolter<sup>1</sup>, Aditi Raghunathan<sup>1</sup>
    </h3>
    <p><sup>1</sup>Carnegie Mellon University</p>
    <div class="buttons">
      <a href="#">arXiv</a>
      <a href="https://github.com" target="_blank"><i class="fab fa-github"></i> GitHub</a>
      <a href="https://twitter.com" target="_blank"><i class="fab fa-twitter"></i> Summary</a>
    </div>
  </header>

  <main>
    <!-- <section class="tldr">
      <h2>TLDR</h2>
      <p>We propose an algorithm to filter web datasets used for training CLIP in order to learn better visual
        representations, and achieve state-of-art zero-shot accuracy on vision tasks.</p>
    </section> -->

    <section class="goal">
      <h2>TLDR</h2>
      <img src="images/cpi.png" alt="CPI">
      <ul>
        <li>LLM's are almost always instruction finetuned to improve their ability to follow the user instruction and
          better comprehend the input context.</li>
        <li>However, state-of-the-art models still struggle to rely on the context, especially when it is not aligned
          with parametric knowledge.</li>
        <li>We observe an <i>intriguing</i> phenomenon: contrary to the expectation, context reliance infact
          decreases with instruction finetuning, despite an initial expected increase. </li>
      </ul>
    </section>
  </main>

</body>

</html>